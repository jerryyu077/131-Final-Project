{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Load the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/Amen/Desktop/default of credit card clients.xls'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-03f9ca42a2e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"C:/Users/Amen/Desktop/default of credit card clients.xls\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, **kwds)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     return io.parse(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, io, **kwds)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# a ZIP file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/Amen/Desktop/default of credit card clients.xls'"
     ]
    }
   ],
   "source": [
    "data=pd.read_excel(\"default of credit card clients.xls\",header=1)\n",
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 30000 obervations and 25 variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by looking to the data features (default by first 5 rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking missing values in variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the data description and table shows above, there is no missing or nan values in our data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Distinguish categorical and continuous variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to distinguish categorical and continuous variables. When unique value in a variable greater than 15, we consider as continuous variables otherwise we consider as categorical variable. Seperating continuous and categorical variables will help us to summary statistics better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_v = []\n",
    "con_v = []\n",
    "for c in data.columns:\n",
    "    if len(data[c].value_counts().index)<=15:\n",
    "        cat_v.append(c)\n",
    "    else:\n",
    "        con_v.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The continuous variables: \", con_v, \"\\n\")\n",
    "print(\"The categorical variables: \", cat_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Basic feature analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look more details to the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. continuous variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we want to analyst continuous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data[con_v].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 30,000 credit card clients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean of credit card balance limit is 167,484. The standard deviation is extremely large and unusual, we noticed that the max value is 1 millions that is much larger than Q3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average age is around 36 year old with standard deviation of 9.2. Minimum age is 21 and maximum age is 79."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other variables are people month bills and month payments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii.categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data[cat_v], dtype='object').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More than half clients are women."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Education level is mostly university."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Half of clients are single."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of couse, most of clients have no payment issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[\"default payment next month\"].plot(kind=\"hist\")\n",
    "plt.xticks(range(0,2,1))\n",
    "plt.xlabel(\"Payment=0,Not Default Payment=1\")\n",
    "plt.title(\"Default payment next month\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on graph and describe,there are 23364 clients without default payment and 6639 clients with default payment in 2005. Also, base on the graph variable \"default payment next month\" as our target variable has not a large unbalance values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"default payment next month\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22.12% card holder are default payment and 77.88% card horlder without default payment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Credit Card limitation distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,5))\n",
    "plt.title('Amount of credit limit')\n",
    "sns.distplot(data['LIMIT_BAL'],kde=True,bins=200, color=\"blue\")\n",
    "plt.xticks(range(0,1000000,250000))\n",
    "plt.ylabel('Percentage %')\n",
    "plt.xlabel('Credit Card limit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"LIMIT_BAL\"].value_counts().head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot shows that largest group with credit card limit is 50K group and second largest group of clients with credit card limit is 20K group. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The credit card limit is a right tail distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Credit Card Limitation Distribution,Group by Gender** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now,we want to see is there a difference between people who is creaditable or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0 = data.loc[data['default payment next month'] == 0][\"LIMIT_BAL\"]\n",
    "class_1 = data.loc[data['default payment next month'] == 1][\"LIMIT_BAL\"]\n",
    "plt.figure(figsize = (12,4))\n",
    "sns.distplot(class_1,kde=True,bins=200, color=\"red\")\n",
    "sns.distplot(class_0,kde=True,bins=200, color=\"blue\")\n",
    "plt.title(\"Default amount of credit limit,Group by default payment next month\")\n",
    "plt.legend([\"Default\",\"Not Default\"])\n",
    "plt.xticks(range(0,1000000,250000))\n",
    "plt.ylabel('Percentage %')\n",
    "plt.xlabel('Credit Card limit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of not creditable people have credit card limit around 20K to 50K. The clients without default payment have higher limit than people who with default payment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gender**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, we want to see it there have a gender discrimination with credit card limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "sns.boxplot(x=\"SEX\",y=\"LIMIT_BAL\",data=data,hue=\"SEX\")\n",
    "plt.ylabel('Credit Card limit')\n",
    "plt.xlabel(\"Gender\")\n",
    "plt.title(\"Default amount of credit card limit,Group by gender\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows that male and female have similar credit card limit, so that gender may not be a great variables to use in classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Female has a outler, but we think it is acceptable since maybe she is a CEO of some company and she has enough credit to loan more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the if there are linear relationships between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr(df,size=15):\n",
    "    corr = df.corr()\n",
    "    fig, ax = plt.subplots(figsize=(size, size))\n",
    "    cax = ax.matshow(corr,cmap=plt.get_cmap('rainbow'))\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns)\n",
    "    plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "    plt.colorbar(cax)\n",
    "plot_corr(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main part of correlation, one is PAY variables and Bill variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corrlation of payment status is decreasing by times go on. From current month to past month or next month have highest correlation.  The lowest correlation is between September and April. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, corrlation of bill is decreasing by times go on. From current month to past month or next month have highest correlation. And the lowest correlation is between September and April. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Credit Card limitation,group by Age and Gender(Side-by-side Barplot)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(ncols=1, figsize=(16,6))\n",
    "sns.boxplot(ax=ax1, x=\"AGE\", y=\"LIMIT_BAL\", hue=\"SEX\",data=data)\n",
    "plt.ylabel('Credit Card limit')\n",
    "plt.xlabel(\"AGE\")\n",
    "plt.title(\"Default amount of credit card limit,group by age and sex\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean of credit card limit is increasing from age 21 to age 35. And after 35 years old, the mean of limit is remain stable and it's little bit decreasing from 40 to 60. The obvious difference between male and female is age 65 to age 79, those age have extreme large diffences, for example, at age 39,48 until 60, the mean value for males are much larger than female."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Marriage**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may thinking about the marriage is a main factor to effect a person who with/without default payment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"MARRIAGE\", data=data,hue=\"default payment next month\", palette=\"muted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the plot shows, marriage people have less default payment issue compare with single people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It states that marriage status is a factor to effect a default payment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the train data and test data\n",
    "random.seed(777)\n",
    "train_data = data.sample(frac=5/6, replace=False)\n",
    "test_data = data.sample(frac=1/6, replace=False)\n",
    "print (train_data.shape)\n",
    "print (test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data['default payment next month']\n",
    "y_test=test_data['default payment next month']\n",
    "x_train = train_data.drop(['default payment next month', 'ID'], axis= 1)\n",
    "x_test = test_data.drop(['default payment next month', 'ID'], axis= 1)\n",
    "print (y_train.shape)\n",
    "print (y_test.shape)\n",
    "print (x_train.shape)\n",
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used random forest tree model as my first baseline model since:\n",
    "1. By principle since it randomizes the variable selection during each tree split it's not prone to overfit unlike other models.\n",
    "2. We don't need to pre-precessing data too much.\n",
    "3. I used to read that RF don't need CV because it has includes bootstrap sampling and random variable selection in the process of model fit."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Random Forester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF = RandomForestClassifier(class_weight = {0:1, 1:3})\n",
    "RF.fit(x_train, y_train)\n",
    "y_pred = RF.predict(x_test)\n",
    "acc_RF = round(accuracy_score(y_test,y_pred) * 100, 2)\n",
    "print(RF.score(x_train, y_train))\n",
    "print (acc_RF)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We can see the score is not too far away from the test predition, so it's not overfiting."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We use the Grid search cross validation to fine-tune the parameter for random forester model, which also can help use prevent the model overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame()\n",
    "features['feature'] = x_train.columns\n",
    "features['importance'] = RF.feature_importances_\n",
    "features = features.sort_values(by='importance',ascending=False)\n",
    "plt.figure(figsize = (7,4))\n",
    "plt.title('Features importance',fontsize=14)\n",
    "s = sns.barplot(x='feature',y='importance',data=features)\n",
    "s.set_xticklabels(s.get_xticklabels(),rotation=90)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "From the plot, we can see the most important seven columns are PAY_0, AGE, BILL_AMT1, LIMIT_BAL, BILL_AMT2, PAY_AMT1ï¼ŒPAY_AMT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "def search_model(x_train, y_train, est, param_grid, n_jobs, cv):\n",
    "    model = GridSearchCV(estimator  = est,\n",
    "                                     param_grid = param_grid,\n",
    "                                     scoring = 'f1_weighted',\n",
    "                                     verbose = 10,\n",
    "                                     n_jobs = n_jobs,\n",
    "                                     iid = True,\n",
    "                                     cv = cv)\n",
    "    # Fit Grid Search Model\n",
    "    model.fit(x_train, y_train)   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid search is actually using cross validation method to tune parameters, \n",
    "## which is to scan all posible parameter combinations and return the best one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators':[100,300,500],\n",
    "             'criterion':['gini', 'entropy'],\n",
    "             'class_weight': [{0:1, 1:3}]}\n",
    "\n",
    "RF = search_model(x_train, y_train\n",
    "            , RandomForestClassifier()\n",
    "            , param_grid\n",
    "            , -1\n",
    "            , 5)\n",
    "RF.fit(x_train, y_train)\n",
    "y_pred = RF.predict(x_test)\n",
    "acc_RF = round(accuracy_score(y_test,y_pred) * 100, 2)\n",
    "print(RF.score(x_train, y_train))\n",
    "print (acc_RF)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "After tune the parameters, the predicting accuracy reach up to 97.24%, and the model score accuracy reach up to 99.95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred_log = model.predict(x_test)\n",
    "acc_log = round(accuracy_score(y_test,y_pred_log) * 100, 2)\n",
    "print (acc_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logisticCV\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "model = LogisticRegressionCV()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred_logcv = model.predict(x_test)\n",
    "acc_logcv = round(accuracy_score(y_test,y_pred_logcv) * 100, 2)\n",
    "print (acc_logcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred_svc = model.predict(x_test)\n",
    "acc_svc = round(accuracy_score(y_test,y_pred_svc) * 100, 2)\n",
    "print (acc_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear SVM\n",
    "from sklearn.svm import LinearSVC\n",
    "model = LinearSVC()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred_lsvc = model.predict(x_test)\n",
    "acc_lsvc = round(accuracy_score(y_test,y_pred_lsvc) * 100, 2)\n",
    "print (acc_lsvc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred_knn = model.predict(x_test)\n",
    "acc_knn = round(accuracy_score(y_test,y_pred_knn) * 100, 2)\n",
    "print (acc_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred_DT = model.predict(x_test)\n",
    "acc_DT = round(accuracy_score(y_test,y_pred_DT) * 100, 2)\n",
    "print (acc_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred_GNB = model.predict(x_test)\n",
    "acc_GNB = round(accuracy_score(y_test,y_pred_GNB) * 100, 2)\n",
    "print (acc_GNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = pd.DataFrame()\n",
    "acc['accuracy'] = [acc_RF,acc_log,acc_logcv,acc_svc,acc_lsvc,acc_knn,acc_DT,acc_GNB]\n",
    "acc['method']=['Random Forester','Logistic','LogisticCV',\"SVM\",\n",
    "               \"Linear SVM\",\"KNN\",\"Decision Tree\",'Gaussian Naive Bayes']\n",
    "acc.index=acc.method\n",
    "acc = acc.sort_values(by='accuracy',ascending=False)\n",
    "print(acc.drop(['method'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (7,4))\n",
    "plt.title('Accuracy',fontsize=14)\n",
    "s = sns.barplot(x='method',y='accuracy',data=acc)\n",
    "s.set_xticklabels(s.get_xticklabels(),rotation=90)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "After comparing all the models, we can see the random forester is the best predicting model for this dataset."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
